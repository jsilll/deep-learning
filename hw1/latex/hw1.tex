\documentclass[12pt]{article}

\usepackage{url}
\usepackage{color}
\usepackage{float}
\usepackage{array}
\usepackage{xcolor}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{colortbl}
\usepackage{hyperref}
\usepackage{spreadtab}
\usepackage{longtable}
\usepackage{pdflscape}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[margin=1.5cm]{geometry}
\usepackage[format=hang,labelfont=bf,font=small]{caption}
\usepackage{mathtools, amsmath, amsthm, amssymb, amsfonts, mathpartir}

\begin{document}

\title{Homework 1: Deep Learning}
\author{Hugo Mantinhas 95592, Jo√£o Silveira 95597}

\maketitle

\section*{Work Division}

\section*{Question 1}
\begin{itemize}
    \item \textbf{1. a)}
          \begin{figure}[H]
              \centering
              \begin{tabular}{|c|c|c|c|}
                  \toprule
                                      & \textbf{Train} & \textbf{Validation} & \textbf{Test} \\
                  \midrule
                  \textbf{Perceptron} & 0.4654         & 0.4610              & 0.3422        \\
                  \bottomrule
              \end{tabular}
              \label{tab:1.1a}
              \caption{Train and validation accuracies for the perceptron model}
          \end{figure}
          \begin{figure}[H]
              \centering
              \includegraphics[width=\linewidth]{../outputs/hw1-q1-1a.png}
              \caption{Train and validation accuracies for the perceptron model}
              \label{fig:1.1a}
          \end{figure}

    \item \textbf{1. b)} Analysing the plot with the learning rate of 0.01, we find that the weight update many times results in accuracy changes in the order of 5\%, in both directions. This suggests that the weight adjustments might be overshooting the optimal value. On the other hand, the learning rate of 0.001 results in a more stable learning process, with the accuracy changes being in the order of 1\% or less. Unlike the model trained with 0.01 learning rate, this one seems to be tending to grow over time. This suggests that the weight adjustments are closer to the optimal value. Although the accuracies don't look much different: 0.5784 for learning rate 0.01 and 0.5936 for learning rate 0.001; for the latter it shows a lot more stability in its accuracy across epochs.
          \begin{figure}[H]
              \centering
              \includegraphics[width=1\linewidth]{../outputs/hw1-q1-1b.01.png}
              \includegraphics[width=1\linewidth]{../outputs/hw1-q1-1b.001.png}
              \caption{Train and validation accuracies for learning rates of 0.01 and 0.001}
              \label{fig:1.1b}
          \end{figure}
          \begin{figure}[H]
              \centering
              \begin{tabular}{|c|c|c|c|}
                  \toprule
                                               & \textbf{Train} & \textbf{Validation} & \textbf{Test} \\
                  \midrule
                  \textbf{Learning rate 0.01}  & 0.6609         & 0.6568              & 0.5784        \\
                  \textbf{Learning rate 0.001} & 0.6625         & 0.6639              & 0.5936        \\
                  \bottomrule
              \end{tabular}
              \label{tab:1.1b}
              \caption{Train and validation accuracies for learning rates of 0.01 and 0.001}
          \end{figure}
    \item \textbf{2. a)} This statement is true. A logistic regression model is a linear model, which means that it can only learn linearly separable data. On the other hand, a multi-layer perceptron using relu activations can learn to separate non-linearly separable data because of the non-linearity introduced by the relu activation function in between layers. However, it can be shown, by computing the Hessian matrix of the loss function, that the loss function of a logistic regression model using cross-entropy loss is always convex, while the loss function of a multi-layer perceptron, in general, is not. This means that the logistic regression model can be trained to a global optimum, while, with a multi-layer perceptron, we can never be sure that we have reached a global optimum.

    \item \textbf{2. b)} Final test accuracy: 0.7580
          \begin{figure}[H]
              \centering
              \includegraphics[width=1\linewidth]{../outputs/hw1-q1-2b.001-acc.png}
              \caption{Train and validation accuracies for the no-toolkit MLP}
              \label{fig:1.2b:acc}
          \end{figure}
          \begin{figure}[H]
              \centering
              \includegraphics[width=1\linewidth]{../outputs/hw1-q1-2b.001-loss.png}
              \caption{Train loss for the no-toolkit MLP}
              \label{fig:1.2b:loss}
          \end{figure}
\end{itemize}

\section*{Question 2}
\begin{itemize}
    \item \textbf{1. )} The best configuration in terms of validation accuracy was the one with learning rate 0.01 with a final test accuracy of 0.6200.
          \begin{figure}[H]
              \centering
              \includegraphics[width=0.5\linewidth]{../outputs/hw1-q2-1-acc.01.png}
              \caption{Train and validation accuracies for the logistic regression model with learning rate 0.01}
              \label{fig:2.1:acc}
          \end{figure}
          \begin{figure}[H]
              \centering
              \includegraphics[width=0.5\linewidth]{../outputs/hw1-q2-1-loss.01.png}
              \caption{Train loss for the logistic regression model with learning rate 0.01}
              \label{fig:2.1:loss}
          \end{figure}

    \item \textbf{2. a)}
          Choosing the right batch size implies dealing with a trade-off between speed of training, and accuracy of results. The larger the batch size, less frequently does the network update its own weights, meaning that it must do less non parallelizable computations, resulting in lower training times. However, updating the network weights less frequently 
          
This is how I understand it.

    When the batch size is small , the gradients are generally bigger and chaotic. This is because a incorrect value in one of the data point prediction could lead a larger loss when batch size is 2 as compared to 4 (or 16 as compared to 32). This makes the model move closer towards the local optima of that one particular batch at a time.

    As you train your model, you will realize that the accuracy really doesn't get any better after lesser number of epoch , that is becuase , after sometime these sporadic changes in the value of gradients doesn't work. we need a bigger batch for our model to generalize well quickly.

So, small batches will give fast gradient updates, but the accuracy will stagnate quickly. Larger batches will increase the accuracy very slowly , but will keep doing it for longer number of epochs and will lead to better overall accuracy in longer term.

This is why batch_size is also a hyperparameter and needs to be tuned.

In practice, I have changed the batch_size mid training to gain these benefits but frankly it is almost never worth it. Just run your epoch on somewhat optimal batch_size.

          The batch size can be understood as a trade-off between accuracy and speed. Large batch sizes can lead to faster training times but may result in lower accuracy and overfitting, while smaller batch sizes can provide better accuracy, but can be computationally expensive and time-consuming.
          \begin{figure}[H]
              \centering
              \begin{tabular}{|c|cc|}
                  \toprule
                  \textbf{Batch Size} & \textbf{Test Accuracy} & \textbf{Execution time} \\
                  \midrule
                  \textbf{16}         & \underline{0.7788}                 & 1min17.420sec        \\
                  \textbf{1024}       & 0.7208                 & 0min22.466sec        \\
                  \bottomrule
              \end{tabular}
              \caption{Comparison of 16 and 1024 batch sizes for the logistic regression}
              \label{tab:2.2a}
          \end{figure}
          \begin{figure}[H]
              \centering
              \includegraphics[width=0.5\linewidth]{../outputs/hw1-q2-2a-acc-16.png}
              \caption{Train and validation accuracies for the feed-forward using a batch size of 16}
              \label{fig:2.2a:acc:16}
          \end{figure}
          \begin{figure}[H]
              \centering
              \includegraphics[width=0.5\linewidth]{../outputs/hw1-q2-2a-loss-16.png}
              \caption{Train loss for the feed-forward using a batch size of 16}
              \label{fig:2.2a:loss:16}
          \end{figure}
          \begin{figure}[H]
              \centering
              \includegraphics[width=0.5\linewidth]{../outputs/hw1-q2-2a-acc-1024.png}
              \caption{Train and validation accuracies for the feed-forward using a batch size of 1024}
              \label{fig:2.2a:acc:1024}
          \end{figure}
          \begin{figure}[H]
              \centering
              \includegraphics[width=0.5\linewidth]{../outputs/hw1-q2-2a-loss-1024.png}
              \caption{Train loss for the feed-forward using a batch size of 1024}
              \label{fig:2.2a:loss:1024}
          \end{figure}
\end{itemize}

\section*{Question 3}
\begin{itemize}
    \item \textbf{1. a)} For the case with $D=2, A=-1, B=1$, there are 4 data points in our domain, calculated in Figure \ref{fig:3a:calc}, and represented in Figure \ref{fig:3a:graph}

          \begin{figure}[H]
              \begin{minipage}{0.5\linewidth}
                  \begin{equation*}
                      f(-1, 1):
                  \end{equation*}
                  \begin{equation*}
                      \sum_{i=1}^{2} x_i = -1 + 1 = 0
                  \end{equation*}
                  \begin{equation*}
                      0 \in [-1, 1] \Rightarrow f(-1, 1) = 1
                  \end{equation*}

                  \begin{equation*}
                      f(-1, -1):
                  \end{equation*}
                  \begin{equation*}
                      \sum_{i=1}^{2} x_i = -1 + -1 = -2
                  \end{equation*}
                  \begin{equation*}
                      -2 \notin [-1, 1] \Rightarrow f(-1, -1) = -1
                  \end{equation*}
              \end{minipage}
              \begin{minipage}{0.5\linewidth}
                  \begin{equation*}
                      f(1, 1):
                  \end{equation*}
                  \begin{equation*}
                      \sum_{i=1}^{2} x_i = 1 + 1 = 2
                  \end{equation*}
                  \begin{equation*}
                      2 \notin [-1, 1] \Rightarrow f(1, 1) = -1
                  \end{equation*}

                  \begin{equation*}
                      f(1, -1):
                  \end{equation*}
                  \begin{equation*}
                      \sum_{i=1}^{2} x_i = 1 + (-1) = 0
                  \end{equation*}
                  \begin{equation*}
                      0 \in [-1, 1] \Rightarrow f(1, -1) = 1
                  \end{equation*}
              \end{minipage}
              \caption{Calculation of $f(x)$ for $D=2, A=-1, B=1$}
              \label{fig:3a:calc}
          \end{figure}

          \begin{figure}[H]
              \centering
              \includegraphics[width=0.5\linewidth]{../outputs/hw1-q3-a.png}
              \caption{Space of $f(x)$ for $D=2, A=-1, B=1$. Green represents class 1 and red represents class -1.}
              \label{fig:3a:graph}
          \end{figure}

          For this example, we can see that the data is not linearly separable, since it is equivalent to the XOR problem which is also not linearly separable. For this reason, we can conclude we cannot use a single perceptron to classify this data.

\end{itemize}

\end{document}
